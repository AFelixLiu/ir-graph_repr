{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "metadata": {
   "interpreter": {
    "hash": "fb3e69b1849fbe3db38258675c90eca9b4601c3e4a5f4e71200d2f3e80de7811"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T15:20:17.609026Z",
     "start_time": "2024-07-28T15:20:17.494106Z"
    }
   },
   "source": [
    "import pickle\n",
    "from random import shuffle, seed\n",
    "import numpy as np"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T15:20:19.937018Z",
     "start_time": "2024-07-28T15:20:17.611039Z"
    }
   },
   "source": [
    "seed(13)\n",
    "\n",
    "with open(\"Cleaner NIST Dataset.pickle\", \"rb\") as f:\n",
    "    d = pickle.load(f)\n",
    "smiles = d[\"smiles\"]\n",
    "sequences = d[\"sequences\"]\n",
    "# Zip each data sequence.\n",
    "dataset = list(zip(smiles, sequences))\n",
    "shuffle(dataset)\n",
    "\n",
    "# Extract compounds that occur more than once so that repeats aren't distributed across folds.\n",
    "single_occurrence_molecules = [x for x in dataset if list(d[\"smiles\"]).count(x[0]) <= 1]\n",
    "multiple_occurrence_molecules = [x for x in dataset if x[0] not in [h[0] for h in single_occurrence_molecules]]\n",
    "\n",
    "# Create folds.\n",
    "folds = {}\n",
    "fold_size = len(single_occurrence_molecules) // 5\n",
    "for i in range(1, 6):\n",
    "    folds[i] = single_occurrence_molecules[((i - 1) * fold_size):(i * fold_size)]\n",
    "# Add whatever wasn't added from single occurrences to the end of multiple occurrences.\n",
    "multiple_occurrence_molecules += single_occurrence_molecules[(5 * fold_size):]\n",
    "mult_fold_size = len(multiple_occurrence_molecules) // 5\n",
    "# Add all these molecules across folds such that all repeat occurrences always occur within the same fold.\n",
    "current_fold = 0\n",
    "while len(multiple_occurrence_molecules) > 0:\n",
    "    current_fold %= 5\n",
    "    current_fold += 1\n",
    "    current_molecule = multiple_occurrence_molecules[0]\n",
    "    while current_molecule[0] in [h[0] for h in multiple_occurrence_molecules]:\n",
    "        folds[current_fold].append(multiple_occurrence_molecules.pop([h[0] for h in multiple_occurrence_molecules].index(current_molecule[0])))"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T15:20:29.685045Z",
     "start_time": "2024-07-28T15:20:19.939050Z"
    }
   },
   "source": [
    "def normalize(s):\n",
    "    \"\"\"\n",
    "    Normalize the input series from 0->1 and return it.\n",
    "    \"\"\"\n",
    "    # 找到输入序列中的最大值\n",
    "    max_val = max(s)\n",
    "    # 计算缩放比例\n",
    "    scale = 1 / max_val\n",
    "    # 如果最大值为 0，则将缩放比例设为 0\n",
    "    if max_val == 0:\n",
    "      scale = 0\n",
    "    # 通过列表推导式对输入序列进行缩放\n",
    "    return [j * scale for j in s]\n",
    "\n",
    "def normal_many(x):\n",
    "    # 对输入的多个序列分别调用 normalize 函数并进行 floor_out 处理\n",
    "    return [floor_out(normalize(j)) for j in x]\n",
    "\n",
    "def floor_out(x):\n",
    "    # 通过列表推导式对输入序列进行处理，将小于 0.01 的值设为 0\n",
    "    return [j if j > 0.01 else 0 for j in x]\n",
    "\n",
    "dataset_splits = {1: {}, 2: {}, 3: {}, 4: {}, 5: {}}\n",
    "for i in range(1, 6):\n",
    "    # For each i-th split, the testing set will be the i-th fold.\n",
    "    test = folds[i]\n",
    "    train = []\n",
    "    for x in range(1, 6):\n",
    "        if x != i:\n",
    "            train += folds[x]\n",
    "            \n",
    "    dataset_splits[i][\"test_smiles\"] = np.array([j[0] for j in test])\n",
    "    dataset_splits[i][\"test_y\"] = np.array(normal_many([j[1] for j in test]), dtype = float)\n",
    "    dataset_splits[i][\"train_smiles\"] = np.array([j[0] for j in train])\n",
    "    dataset_splits[i][\"train_y\"] = np.array(normal_many([j[1] for j in train]), dtype = float)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-28T15:20:29.700612Z",
     "start_time": "2024-07-28T15:20:29.687048Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": 3
  }
 ]
}
